{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install lxml\n",
    "#!pip install -U splinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import requests\n",
    "import lxml.html as lh\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func\n",
    "from config import pw\n",
    "import time\n",
    "from splinter import Browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'find'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ce5a8bf4c7b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbsoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbsoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"spry:region2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'table'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mcolumn_headers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Company'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'City'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'State'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Owner/Maker'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2159\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2160\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m   2161\u001b[0m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'find'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "url = 'http://flavorsofcacao.com/usa_craft_makers.html'\n",
    "browser.visit(url)\n",
    "time.sleep(2)\n",
    "html = browser.html\n",
    "#print(html)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "bsoup = soup(html, 'html.parser')\n",
    "time.sleep(4)\n",
    "print(bsoup)\n",
    "results = bsoup.find(id=\"spryregion2\")\n",
    "results = results.find_all('table')[0]\n",
    "column_headers = ['Company','City', 'State', 'Owner/Maker']\n",
    "records = []\n",
    "for idy, row in enumerate(results.findAll('tr')):\n",
    "    if idy == 0:\n",
    "        continue\n",
    "    cols = row.findAll('td')\n",
    "    record = {}\n",
    "    for idx, col in enumerate(cols):\n",
    "        record[column_headers[idx]] = col.text.strip()\n",
    "    records.append(record)\n",
    "browser.quit()\n",
    "df = pd.DataFrame.from_dict(records)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cacao_csv = \"Resources/flavors_of_cacao.csv\"\n",
    "# cacao_df = pd.read_csv(cacao_csv, encoding=\"utf-8\")\n",
    "# cacao_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chocolate_csv = \"Resources/chocolate_2020.csv\"\n",
    "chocolate_df = pd.read_csv(chocolate_csv, encoding =\"utf-8\")\n",
    "chocolate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_choc = chocolate_df.drop(['Unnamed: 0','ref', 'review_date', 'specific_bean_origin_or_bar_name', 'rating', 'counts_of_ingredients', 'first_taste', 'second_taste', 'third_taste', 'fourth_taste','lecithin', 'sweetener_without_sugar',], axis=1)\n",
    "\n",
    "new_choc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_choc = new_choc.loc[new_choc[\"company_location\"]==\"U.S.A\"]\n",
    "final_choc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_csv = \"Resources/usa_chocolate.csv\"\n",
    "us_chocolate = pd.read_csv(us_csv, encoding = \"utf-8\")\n",
    "us_chocolate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_choc = us_chocolate.drop(['CITY','OWNER/MAKER'], axis = 1)\n",
    "us_choc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'postgres'\n",
    "password = pw\n",
    "engine = create_engine(f'postgresql://{username}:{password}@localhost:5432/chocolate_db')\n",
    "connection = engine.connect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://flavorsofcacao.com/usa_craft_makers.html\"\n",
    "tables = pd.read_html(url)\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://flavorsofcacao.com/usa_craft_makers.html'\n",
    "browser.visit(url)\n",
    "time.sleep(2)\n",
    "html = browser.html\n",
    "#print(html)\n",
    "bsoup = soup(html, 'html.parser')\n",
    "time.sleep(4)\n",
    "print(bsoup)\n",
    "results = bsoup.find(id=\"spryregion2\")\n",
    "results = results.find_all('table')[0]\n",
    "column_headers = ['Company','City', 'State', 'Owner/Maker']\n",
    "records = []\n",
    "for idy, row in enumerate(results.findAll('tr')):\n",
    "    if idy == 0:\n",
    "        continue\n",
    "    cols = row.findAll('td')\n",
    "    record = {}\n",
    "    for idx, col in enumerate(cols):\n",
    "        record[column_headers[idx]] = col.text.strip()\n",
    "    records.append(record)\n",
    "browser.quit()\n",
    "df = pd.DataFrame.from_dict(records)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://flavorsofcacao.com/usa_craft_makers.html\"\n",
    "# response = requests.get(url)\n",
    "# soup = BeautifulSoup(response.text, 'lxml')\n",
    "browser.visit(url)\n",
    "html = =browser.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = soup.find_all('tr', attrs={'class': 'TableName'})\n",
    "#results = soup.find_all('tr', class_=\"TableName\")\n",
    "time.sleep(3)\n",
    "results = soup.find_all('tr', class_='TableName')\n",
    "\n",
    "for result in results:\n",
    "    company = result.find_all('td')\n",
    "    #state = results.find_all('td')\n",
    "        \n",
    "\n",
    "#     print ('\\n------------------------\\n')\n",
    "#     print(company)\n",
    "#     print(state)\n",
    "print(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://flavorsofcacao.com/usa_craft_makers.html\"\n",
    "# response = requests.get(url).text\n",
    "soup = BeautifulSoup(url, \"lxml\")\n",
    "comp_name = []\n",
    "city = []\n",
    "state = []\n",
    "owner = []\n",
    "\n",
    "for table in soup.find_all(attrs={\"class\": \"TableName\"}):\n",
    "    time.\n",
    "    response = requests.get(url).text\n",
    "    for response in response:\n",
    "        xyz = soup.find_all(\"td\")\n",
    "        \n",
    "#     xyz = response.find_all(\"td\")\n",
    "#     for tr in soup.find_all(\"td\"):\n",
    "#         comp_name.append(response[\"COMPANY NAME\"])\n",
    "#         city.append(response[1])\n",
    "#         state.append(response[2])\n",
    "#         owner.append(response[3])\n",
    "    #print(xyz)\n",
    "        \n",
    "#choc_list = choc_table.find_all(\"td\")\n",
    "# headings = []\n",
    "# for i in choc_table.find_all(\"td\"):\n",
    "#     headings.append(['COMPANY_NAME'],['CITY'],['STATE'],['OWNER/MAKER'])\n",
    "#choc_table\n",
    "print(xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://flavorsofcacao.com/usa_craft_makers.html\"\n",
    "response = requests.get(url).text\n",
    "soup = BeautifulSoup(content, \"lxml\")\n",
    "choc_table = soup.find_all(attrs={\"class\": \"TableName\"})\n",
    "comp_name = []\n",
    "city = []\n",
    "state = []\n",
    "owner = []\n",
    "for table in choc_table:\n",
    "    xyz = soup.find_all(\"td\")\n",
    "    comp_name.append(response[5])\n",
    "    city.append(response[1])\n",
    "    state.append(response[2])\n",
    "    owner.append(response[3])\n",
    "#     comp_name.append(response[\"COMPANY_NAME\"])\n",
    "#     city.append(response[\"CITY\"])\n",
    "#     state.append(response[\"STATE\"])\n",
    "#     owner.append(response[\"OWNER/MAKER\"])\n",
    "    #print(xyz)\n",
    "#choc_list = choc_table.find_all(\"td\")\n",
    "# headings = []\n",
    "# for i in choc_table.find_all(\"td\"):\n",
    "#     headings.append(['COMPANY_NAME'],['CITY'],['STATE'],['OWNER/MAKER'])\n",
    "#choc_table\n",
    "print(comp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://flavorsofcacao.com/usa_craft_makers.html\"\n",
    "content = requests.get(url).text\n",
    "\n",
    "soup = BeautifulSoup(content, \"lxml\")\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_table = soup.find_all(\"div\", attrs={\"spry:region\": \"ds3\"})\n",
    "gdp_table_data = gdp_table.find_all(\"tr\")  # contains 2 rows\n",
    "\n",
    "# Get all the headings of Lists\n",
    "headings = []\n",
    "for td in gdp_table_data[0].find_all(\"td\"):\n",
    "    # remove any newlines and extra spaces from left and right\n",
    "    headings.append(td.b.text.replace('\\n', ' ').strip())\n",
    "\n",
    "print(headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://flavorsofcacao.com/usa_craft_makers.html')\n",
    "pd.read_html(r.text)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tables = pd.read_html(\"http://flavorsofcacao.com/usa_craft_makers.html\", header = 0, keep_default_na=False\n",
    "# headings = ['COMPANY NAME', 'CITY', 'STATE', 'OWNER/MAKER']\n",
    "url = \"http://flavorsofcacao.com/usa_craft_makers.html\"\n",
    "content = requests.get(url).text\n",
    "soup = BeautifulSoup(content, \"lxml\")\n",
    "\n",
    "for table in content:\n",
    "    soup.find_all(attrs={\"class\": \"TableName\"})\n",
    "    for name in TabelName:\n",
    "          soup.find_all(\"td\")\n",
    "    else: \n",
    "        break \n",
    "\n",
    "\n",
    "# table['Country name'].replace({r'.*!(.*)': r'\\1'}, regex=True, inplace=True)\n",
    "# table[headings].to_csv('test.txt', sep=';', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= tables[3]\n",
    "df.columns = ['COMPANY NAME', 'CITY', 'STATE', 'OWNER/MAKER']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = requests.get('http://flavorsofcacao.com/usa_craft_makers.html')\n",
    "soup = BeautifulSoup(c.content, \"lxml\")\n",
    "table = soup.find_all('table')[0] \n",
    "df = pd.read_html(str(table))\n",
    "print(df[0].to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python38364bitpythondataconda5a1651f5006c42e28f55073acdf8b1f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
